{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size, input_shape, n_actions, discrete=False):\n",
    "        self.mem_size = max_size\n",
    "        \n",
    "        #rather than deque, use set np arrays, track index last saved\n",
    "        #store tuple of reward, q-vals, next state for experience replay\n",
    "        self.mem_counter = 0 \n",
    "        self.discrete = discrete\n",
    "        \n",
    "        #allocate table equal to rows of mem entries with cols of env observations (e.g. for lunar lander-> 8 possibile results)\n",
    "        self.state_memory = np.zeros((self.mem_size, input_shape))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, input_shape))\n",
    "        dtype = np.int8 if self.discrete else np.float32 #for continuous actions: decimals; discrete space: int w/ 8 possibilities\n",
    "        \n",
    "        #set dtype to index np array for experience replay, table will store either int or decimals depending on dtype \n",
    "        self.action_memory = np.zeros((self.mem_size, n_actions), dtype=dtype) #possible actions for lunar lander-> 4\n",
    "        self.new_state_memory = np.zeros((self.mem_size, input_shape))\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        #sampling transitions for eps, future reward at terminal state is zero, must accomodate and store incase\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        \n",
    "    #add transitions to mem    \n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_counter % self.mem_size #ensure mem overwritten when mem_size surpassed \n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        if self.discrete:\n",
    "            #retrieve num actions from cols of action_mem if discrete space\n",
    "            actions = np.zeros(self.action_memory.shape[1])\n",
    "            #provide one-hot encoding for selected action\n",
    "            #ex: [0, 0, 0, 1, 0, 0, 0, 0] -> at state x, agent takes actions[3] = 1, goes to state_ y\n",
    "            actions[action] = 1.0\n",
    "            #store entire arr of actions at each index in mem\n",
    "            self.action_memory[index] = actions\n",
    "        else:\n",
    "            self.action_memory[action] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = 1 - int(done)\n",
    "        self.mem_counter += 1\n",
    "    \n",
    "    #define sample size for mem; prefer to not have sequential observation samples, else correlations \n",
    "    #agent will inaccurately prioritise certain state-action pairs\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_counter, self.mem_size)\n",
    "        #select batch_size entries from range: [0, max_mem]\n",
    "        batch = np.random.choice(max_mem, batch_size) \n",
    "        states = self.state_memory[batch]\n",
    "        new_states = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "        \n",
    "        return states, actions, rewards, new_states, terminal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dqn(learning_rate, n_actions, input_dims, fc1_dims, fc2_dims):\n",
    "    #input shape has empty placeholder; implies batch provided \n",
    "    model = Sequential([Dense(fc1_dims, input_shape=(input_dims, )),\n",
    "                        Activation('relu'),\n",
    "                        Dense(fc2_dims),\n",
    "                        Activation('relu'),\n",
    "                        Dense(n_actions)])\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNAgent(object):\n",
    "    #epsilon continues decreasing over time to ensure less random actions taken as optimal path will be found \n",
    "    #replace target net weights every 100 eps to update for action eval\n",
    "    def __init__(self, alpha, gamma, n_actions, epsilon, batch_size, input_dims, \n",
    "                 epsilon_dec=0.996, epsilon_end=0.01, mem_size=1000000, fname='ddqn_model.h5',\n",
    "                replace_target=100):\n",
    "        self.n_actions = n_actions\n",
    "        self.action_space = [i for i in range(self.n_actions)]\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_dec = epsilon_dec\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.model_file = fname\n",
    "        self.replace_target = replace_target\n",
    "        self.memory = ReplayBuffer(mem_size, input_dims, n_actions, discrete=True)\n",
    "        self.q_eval = build_dqn(alpha, n_actions, input_dims, 256, 256)\n",
    "        self.q_target = build_dqn(alpha, n_actions, input_dims, 256, 256)\n",
    "        \n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        #insert axis along first-dim (row), ensures single-mem entries can be handled in addition to batches for NN input\n",
    "        state = state[np.newaxis, :]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            #predict defined by keras, runs feed-fwd to compute output (vec of action q-vals)\n",
    "            actions = self.q_eval.predict(state)\n",
    "            action = np.argmax(actions)\n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        #ensure mem > batch so samples have sufficient variance\n",
    "        if self.memory.mem_counter > self.batch_size:\n",
    "            state, action, reward, new_state, done = self.memory.sample_buffer(self.batch_size)\n",
    "            action_values = np.array(self.action_space, dtype=np.int8)\n",
    "            action_indices = np.dot(action, action_values)\n",
    "            \n",
    "            #used to calculate q-val for maximal action selection with behavioral net\n",
    "            q_next = self.q_target.predict(new_state)\n",
    "            q_eval = self.q_eval.predict(new_state)\n",
    "            \n",
    "            #given optimal action, determine q-val with target net\n",
    "            q_pred = self.q_eval.predict(state) #pred state-vals & store in table\n",
    "            \n",
    "            max_actions = np.argmax(q_eval, axis=1) #use behavioral net, q_eval to find best action \n",
    "            q_target = q_pred #evaluate behavioral net, attempt to fit it to optimal policy target net\n",
    "            \n",
    "            batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "            \n",
    "            #apply q_target to find state-vals  & update in table for corresponding actions \n",
    "            q_target[batch_index, action_indices] = reward + self.gamma * q_next[batch_index, max_actions.astype(int)] * done\n",
    "            \n",
    "            #train behavioral net, tune weights to minimise loss (difference); determine q_pred & take diff using it against q_target\n",
    "            #difference applied across all state-val pairs of q_eval against optimal state-val pair of q_target\n",
    "            _ = self.q_eval.fit(state, q_target, verbose=0)\n",
    "            \n",
    "            #gradually adjust epislon to improve runtime as optimal actions taken\n",
    "            self.epsilon = self.epsilon * self.epsilon_dec if self.epsilon > self.epsilon_min else self.epsilon_min\n",
    "            \n",
    "            #update params at threshold\n",
    "            if self.memory.mem_counter % self.replace_target == 0:\n",
    "                self.update_network_parameters()\n",
    "        \n",
    "    #copy weights to target for update \n",
    "    def update_network_parameters():\n",
    "        self.q_target.model.set_weights(self.q_eval.model.get_weights())\n",
    "            \n",
    "    def save_model(self):\n",
    "        self.q_eval.save(self.model_file)\n",
    "        \n",
    "    def load_model(self):\n",
    "        self.q_eval = load_model(self.model_file)\n",
    "        #if model fully trained, update target net\n",
    "        if self.epsilon <= self.epsilon_min:\n",
    "            self.update_network_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLearning(x, scores, epsilons, filename, lines=None):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111, label=\"1\")\n",
    "    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "\n",
    "    ax.plot(x, epsilons, color=\"C0\")\n",
    "    ax.set_xlabel(\"Game\", color=\"C0\")\n",
    "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
    "    ax.tick_params(axis='x', colors=\"C0\")\n",
    "    ax.tick_params(axis='y', colors=\"C0\")\n",
    "\n",
    "    N = len(scores)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
    "\n",
    "    ax2.scatter(x, running_avg, color=\"C1\")\n",
    "    #ax2.xaxis.tick_top()\n",
    "    ax2.axes.get_xaxis().set_visible(False)\n",
    "    ax2.yaxis.tick_right()\n",
    "    #ax2.set_xlabel('x label 2', color=\"C1\")\n",
    "    ax2.set_ylabel('Score', color=\"C1\")\n",
    "    #ax2.xaxis.set_label_position('top')\n",
    "    ax2.yaxis.set_label_position('right')\n",
    "    #ax2.tick_params(axis='x', colors=\"C1\")\n",
    "    ax2.tick_params(axis='y', colors=\"C1\")\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            plt.axvline(x=line)\n",
    "\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -114.60  average score -114.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\envs\\pole-balance\\lib\\site-packages\\keras\\engine\\sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  1 score: -109.20  average score -111.90\n",
      "episode:  2 score: -123.65  average score -115.82\n",
      "episode:  3 score: -144.39  average score -122.96\n",
      "episode:  4 score: -378.90  average score -174.15\n",
      "episode:  5 score: -288.72  average score -193.24\n",
      "episode:  6 score: -117.36  average score -182.40\n",
      "episode:  7 score: -314.41  average score -198.90\n",
      "episode:  8 score: -225.20  average score -201.82\n",
      "episode:  9 score: -552.39  average score -236.88\n",
      "episode:  10 score: -481.56  average score -259.12\n",
      "episode:  11 score: -276.67  average score -260.59\n",
      "episode:  12 score: -169.48  average score -253.58\n",
      "episode:  13 score: -42.38  average score -238.49\n",
      "episode:  14 score: -331.31  average score -244.68\n",
      "episode:  15 score: -127.47  average score -237.35\n",
      "episode:  16 score: -169.68  average score -233.37\n",
      "episode:  17 score: -153.25  average score -228.92\n",
      "episode:  18 score: -182.65  average score -226.49\n",
      "episode:  19 score: -142.60  average score -222.29\n",
      "episode:  20 score: -161.58  average score -219.40\n",
      "episode:  21 score: -140.37  average score -215.81\n",
      "episode:  22 score: -202.60  average score -215.23\n",
      "episode:  23 score: -104.57  average score -210.62\n",
      "episode:  24 score: -138.22  average score -207.73\n",
      "episode:  25 score: -147.89  average score -205.43\n",
      "episode:  26 score: -166.81  average score -204.00\n",
      "episode:  27 score: -163.83  average score -202.56\n",
      "episode:  28 score: -114.68  average score -199.53\n",
      "episode:  29 score: -109.87  average score -196.54\n",
      "episode:  30 score: -190.78  average score -196.36\n",
      "episode:  31 score: -111.44  average score -193.70\n",
      "episode:  32 score: -136.64  average score -191.97\n",
      "episode:  33 score: -223.02  average score -192.89\n",
      "episode:  34 score: -90.99  average score -189.98\n",
      "episode:  35 score: -57.52  average score -186.30\n",
      "episode:  36 score: -115.06  average score -184.37\n",
      "episode:  37 score: -100.67  average score -182.17\n",
      "episode:  38 score: -103.82  average score -180.16\n",
      "episode:  39 score: -30.84  average score -176.43\n",
      "episode:  40 score: -46.30  average score -173.25\n",
      "episode:  41 score: -14.71  average score -169.48\n",
      "episode:  42 score: -13.81  average score -165.86\n",
      "episode:  43 score: -37.99  average score -162.95\n",
      "episode:  44 score: -54.35  average score -160.54\n",
      "episode:  45 score: -25.90  average score -157.61\n",
      "episode:  46 score: -96.60  average score -156.31\n",
      "episode:  47 score: -48.09  average score -154.06\n",
      "episode:  48 score: -13.46  average score -151.19\n",
      "episode:  49 score: -57.18  average score -149.31\n",
      "episode:  50 score: -42.21  average score -147.21\n",
      "episode:  51 score: -37.64  average score -145.10\n",
      "episode:  52 score: -43.64  average score -143.19\n",
      "episode:  53 score: -41.80  average score -141.31\n",
      "episode:  54 score: -78.90  average score -140.17\n",
      "episode:  55 score: -21.04  average score -138.05\n",
      "episode:  56 score: -77.37  average score -136.98\n",
      "episode:  57 score: -18.45  average score -134.94\n",
      "episode:  58 score: -63.49  average score -133.73\n",
      "episode:  59 score: -65.50  average score -132.59\n",
      "episode:  60 score: -34.22  average score -130.98\n",
      "episode:  61 score: 190.85  average score -125.79\n",
      "episode:  62 score: -64.87  average score -124.82\n",
      "episode:  63 score: -1.72  average score -122.90\n",
      "episode:  64 score: -3.57  average score -121.06\n",
      "episode:  65 score: -102.67  average score -120.78\n",
      "episode:  66 score: -24.70  average score -119.35\n",
      "episode:  67 score: -64.51  average score -118.54\n",
      "episode:  68 score: -41.53  average score -117.43\n",
      "episode:  69 score: -11.99  average score -115.92\n",
      "episode:  70 score: -120.43  average score -115.98\n",
      "episode:  71 score: -172.63  average score -116.77\n",
      "episode:  72 score: -44.99  average score -115.79\n",
      "episode:  73 score: -172.23  average score -116.55\n",
      "episode:  74 score: -45.45  average score -115.60\n",
      "episode:  75 score: -94.78  average score -115.33\n",
      "episode:  76 score: -123.09  average score -115.43\n",
      "episode:  77 score: -57.59  average score -114.69\n",
      "episode:  78 score: 35.96  average score -112.78\n",
      "episode:  79 score: -44.54  average score -111.93\n",
      "episode:  80 score: -67.82  average score -111.38\n",
      "episode:  81 score: -67.58  average score -110.85\n",
      "episode:  82 score: -43.12  average score -110.03\n",
      "episode:  83 score: -100.47  average score -109.92\n",
      "episode:  84 score: -493.26  average score -114.43\n",
      "episode:  85 score: 159.83  average score -111.24\n",
      "episode:  86 score: 182.07  average score -107.87\n",
      "episode:  87 score: -32.65  average score -107.01\n",
      "episode:  88 score: 180.95  average score -103.78\n",
      "episode:  89 score: 3.48  average score -102.59\n",
      "episode:  90 score: -14.38  average score -101.62\n",
      "episode:  91 score: -66.98  average score -101.24\n",
      "episode:  92 score: -6.40  average score -100.22\n",
      "episode:  93 score: -32.00  average score -99.49\n",
      "episode:  94 score: -102.79  average score -99.53\n",
      "episode:  95 score: 254.72  average score -95.84\n",
      "episode:  96 score: -31.63  average score -95.18\n",
      "episode:  97 score: 43.98  average score -93.76\n",
      "episode:  98 score: 204.76  average score -90.74\n",
      "episode:  99 score: 179.98  average score -88.04\n",
      "episode:  100 score: -109.63  average score -88.25\n",
      "episode:  101 score: -106.26  average score -88.17\n",
      "episode:  102 score: -61.72  average score -87.70\n",
      "episode:  103 score: 1.48  average score -86.46\n",
      "episode:  104 score: -16.22  average score -85.19\n",
      "episode:  105 score: -64.25  average score -82.07\n",
      "episode:  106 score: -102.10  average score -80.23\n",
      "episode:  107 score: 218.11  average score -76.90\n",
      "episode:  108 score: 170.86  average score -72.10\n",
      "episode:  109 score: -45.79  average score -70.32\n",
      "episode:  110 score: 9.65  average score -64.76\n",
      "episode:  111 score: -12.50  average score -60.11\n",
      "episode:  112 score: 3.92  average score -57.34\n",
      "episode:  113 score: 197.20  average score -53.71\n",
      "episode:  114 score: 141.29  average score -51.89\n",
      "episode:  115 score: -2.21  average score -48.63\n",
      "episode:  116 score: -56.78  average score -47.93\n",
      "episode:  117 score: -12.99  average score -46.38\n",
      "episode:  118 score: -47.43  average score -45.33\n",
      "episode:  119 score: -28.02  average score -43.80\n",
      "episode:  120 score: 135.36  average score -41.05\n",
      "episode:  121 score: -22.80  average score -39.67\n",
      "episode:  122 score: -67.30  average score -38.95\n",
      "episode:  123 score: 7.84  average score -36.87\n",
      "episode:  124 score: -158.41  average score -37.40\n",
      "episode:  125 score: -232.07  average score -38.33\n",
      "episode:  126 score: -156.20  average score -38.41\n",
      "episode:  127 score: -103.28  average score -37.78\n",
      "episode:  128 score: -211.47  average score -38.25\n",
      "episode:  129 score: -84.15  average score -37.95\n",
      "episode:  130 score: -233.64  average score -39.18\n",
      "episode:  131 score: -301.15  average score -40.27\n",
      "episode:  132 score: 17.73  average score -38.99\n",
      "episode:  133 score: -220.98  average score -39.82\n",
      "episode:  134 score: -153.66  average score -39.14\n",
      "episode:  135 score: -74.39  average score -38.97\n",
      "episode:  136 score: -75.80  average score -39.15\n",
      "episode:  137 score: -69.93  average score -38.71\n",
      "episode:  138 score: -60.79  average score -38.31\n",
      "episode:  139 score: -94.90  average score -38.22\n",
      "episode:  140 score: 168.47  average score -36.25\n",
      "episode:  141 score: -67.65  average score -36.46\n",
      "episode:  142 score: -17.36  average score -36.49\n",
      "episode:  143 score: -37.34  average score -36.72\n",
      "episode:  144 score: 228.96  average score -34.08\n",
      "episode:  145 score: 20.14  average score -33.34\n",
      "episode:  146 score: 28.06  average score -32.81\n",
      "episode:  147 score: -46.13  average score -32.31\n",
      "episode:  148 score: 157.49  average score -30.27\n",
      "episode:  149 score: -34.45  average score -30.48\n",
      "episode:  150 score: 183.87  average score -28.09\n",
      "episode:  151 score: -22.11  average score -27.89\n",
      "episode:  152 score: -11.04  average score -27.63\n",
      "episode:  153 score: -69.78  average score -27.89\n",
      "episode:  154 score: 25.17  average score -27.23\n",
      "episode:  155 score: 137.13  average score -25.09\n",
      "episode:  156 score: 185.57  average score -23.04\n",
      "episode:  157 score: 205.00  average score -20.25\n",
      "episode:  158 score: 208.03  average score -18.00\n",
      "episode:  159 score: 10.19  average score -17.27\n",
      "episode:  160 score: 243.26  average score -14.22\n",
      "episode:  161 score: 155.83  average score -12.34\n",
      "episode:  162 score: -37.51  average score -14.60\n",
      "episode:  163 score: -11.28  average score -14.07\n",
      "episode:  164 score: -0.36  average score -14.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  165 score: -3.09  average score -14.05\n",
      "episode:  166 score: -74.62  average score -13.77\n",
      "episode:  167 score: -304.45  average score -16.54\n",
      "episode:  168 score: 216.49  average score -13.76\n",
      "episode:  169 score: -174.83  average score -15.08\n",
      "episode:  170 score: 160.89  average score -13.37\n",
      "episode:  171 score: 207.34  average score -10.12\n",
      "episode:  172 score: 182.79  average score -6.60\n",
      "episode:  173 score: 234.80  average score -3.83\n",
      "episode:  174 score: 141.96  average score -0.72\n",
      "episode:  175 score: 112.55  average score 0.84\n",
      "episode:  176 score: -18.75  average score 1.60\n",
      "episode:  177 score: -100.13  average score 1.82\n",
      "episode:  178 score: 111.18  average score 3.50\n",
      "episode:  179 score: -9.94  average score 3.04\n",
      "episode:  180 score: 114.59  average score 4.62\n",
      "episode:  181 score: -109.75  average score 4.20\n",
      "episode:  182 score: -80.81  average score 4.07\n",
      "episode:  183 score: 250.00  average score 6.97\n",
      "episode:  184 score: 216.53  average score 10.11\n",
      "episode:  185 score: -229.49  average score 12.72\n",
      "episode:  186 score: -16.23  average score 10.98\n",
      "episode:  187 score: 13.85  average score 9.31\n",
      "episode:  188 score: 276.00  average score 12.37\n",
      "episode:  189 score: 195.24  average score 12.51\n",
      "episode:  190 score: 116.65  average score 13.63\n",
      "episode:  191 score: 156.66  average score 15.33\n",
      "episode:  192 score: 252.92  average score 18.49\n",
      "episode:  193 score: -35.08  average score 18.21\n",
      "episode:  194 score: 206.40  average score 20.57\n",
      "episode:  195 score: 214.57  average score 23.71\n",
      "episode:  196 score: 115.46  average score 22.33\n",
      "episode:  197 score: 5.78  average score 22.70\n",
      "episode:  198 score: 186.06  average score 24.11\n",
      "episode:  199 score: 181.10  average score 23.88\n",
      "episode:  200 score: 234.42  average score 24.41\n",
      "episode:  201 score: 163.19  average score 27.12\n",
      "episode:  202 score: 197.87  average score 30.13\n",
      "episode:  203 score: -186.16  average score 28.90\n",
      "episode:  204 score: 24.77  average score 29.13\n",
      "episode:  205 score: 222.78  average score 31.49\n",
      "episode:  206 score: 200.59  average score 34.11\n",
      "episode:  207 score: -75.89  average score 34.37\n",
      "episode:  208 score: 172.62  average score 33.92\n",
      "episode:  209 score: 132.46  average score 33.54\n",
      "episode:  210 score: 221.16  average score 36.19\n",
      "episode:  211 score: 251.22  average score 38.58\n",
      "episode:  212 score: 192.92  average score 40.61\n",
      "episode:  213 score: 204.12  average score 42.59\n",
      "episode:  214 score: 254.86  average score 43.16\n",
      "episode:  215 score: -141.90  average score 40.36\n",
      "episode:  216 score: 211.05  average score 42.47\n",
      "episode:  217 score: 75.86  average score 43.79\n",
      "episode:  218 score: 263.78  average score 46.53\n",
      "episode:  219 score: 204.37  average score 49.02\n",
      "episode:  220 score: 208.01  average score 51.36\n",
      "episode:  221 score: 252.79  average score 52.52\n",
      "episode:  222 score: 233.60  average score 55.06\n",
      "episode:  223 score: 200.23  average score 57.71\n",
      "episode:  224 score: -10.35  average score 57.53\n",
      "episode:  225 score: 208.50  average score 61.16\n",
      "episode:  226 score: 242.68  average score 65.86\n",
      "episode:  227 score: 272.06  average score 70.10\n",
      "episode:  228 score: 237.94  average score 73.48\n",
      "episode:  229 score: 177.57  average score 77.33\n",
      "episode:  230 score: 240.43  average score 80.54\n",
      "episode:  231 score: 212.73  average score 84.96\n",
      "episode:  232 score: 259.86  average score 90.52\n",
      "episode:  233 score: 236.11  average score 92.68\n",
      "episode:  234 score: 262.85  average score 97.47\n",
      "episode:  235 score: 258.32  average score 101.55\n",
      "episode:  236 score: 251.73  average score 104.78\n",
      "episode:  237 score: 188.39  average score 107.39\n",
      "episode:  238 score: 214.31  average score 110.21\n",
      "episode:  239 score: 277.94  average score 113.56\n",
      "episode:  240 score: 119.78  average score 115.69\n",
      "episode:  241 score: -83.45  average score 113.19\n",
      "episode:  242 score: 281.42  average score 116.65\n",
      "episode:  243 score: 268.93  average score 119.48\n",
      "episode:  244 score: 233.64  average score 122.17\n",
      "episode:  245 score: 243.94  average score 122.31\n",
      "episode:  246 score: 259.66  average score 124.69\n",
      "episode:  247 score: 210.17  average score 126.49\n",
      "episode:  248 score: 232.76  average score 129.25\n",
      "episode:  249 score: 230.53  average score 129.97\n",
      "episode:  250 score: 219.15  average score 132.48\n",
      "episode:  251 score: -68.46  average score 129.99\n",
      "episode:  252 score: 92.07  average score 131.12\n",
      "episode:  253 score: 253.85  average score 133.74\n",
      "episode:  254 score: 250.64  average score 136.91\n",
      "episode:  255 score: 265.25  average score 139.29\n",
      "episode:  256 score: 255.28  average score 140.46\n",
      "episode:  257 score: 180.65  average score 140.41\n",
      "episode:  258 score: 218.82  average score 140.55\n",
      "episode:  259 score: 260.39  average score 141.07\n",
      "episode:  260 score: -64.73  average score 140.32\n",
      "episode:  261 score: -120.33  average score 136.72\n",
      "episode:  262 score: 230.83  average score 137.47\n",
      "episode:  263 score: 247.19  average score 140.29\n",
      "episode:  264 score: 315.55  average score 143.52\n",
      "episode:  265 score: 266.31  average score 146.16\n",
      "episode:  266 score: 284.49  average score 149.01\n",
      "episode:  267 score: 211.28  average score 151.84\n",
      "episode:  268 score: 230.94  average score 157.14\n",
      "episode:  269 score: 238.37  average score 157.36\n",
      "episode:  270 score: 311.26  average score 162.17\n",
      "episode:  271 score: 299.85  average score 163.55\n",
      "episode:  272 score: 107.61  average score 162.56\n",
      "episode:  273 score: 166.04  average score 162.39\n",
      "episode:  274 score: 257.77  average score 162.62\n",
      "episode:  275 score: 266.26  average score 163.85\n",
      "episode:  276 score: 251.05  average score 165.22\n",
      "episode:  277 score: 199.73  average score 167.38\n",
      "episode:  278 score: 202.87  average score 170.38\n",
      "episode:  279 score: 205.19  average score 171.32\n",
      "episode:  280 score: 201.84  average score 173.41\n",
      "episode:  281 score: 283.96  average score 175.09\n",
      "episode:  282 score: 300.14  average score 179.15\n",
      "episode:  283 score: 261.51  average score 182.54\n",
      "episode:  284 score: -42.07  average score 179.64\n",
      "episode:  285 score: -10.59  average score 177.40\n",
      "episode:  286 score: 217.41  average score 181.82\n",
      "episode:  287 score: 239.27  average score 184.35\n",
      "episode:  288 score: -112.97  average score 183.09\n",
      "episode:  289 score: 225.13  average score 182.59\n",
      "episode:  290 score: 156.03  average score 182.20\n",
      "episode:  291 score: 267.37  average score 183.70\n",
      "episode:  292 score: 311.74  average score 185.23\n",
      "episode:  293 score: 261.90  average score 185.32\n",
      "episode:  294 score: 254.12  average score 188.18\n",
      "episode:  295 score: 213.47  average score 188.25\n",
      "episode:  296 score: 286.35  average score 188.96\n",
      "episode:  297 score: 248.25  average score 190.28\n",
      "episode:  298 score: 224.81  average score 192.45\n",
      "episode:  299 score: 244.18  average score 193.02\n",
      "episode:  300 score: 208.59  average score 193.29\n",
      "episode:  301 score: 18.56  average score 191.16\n",
      "episode:  302 score: 244.08  average score 191.96\n",
      "episode:  303 score: 294.20  average score 192.91\n",
      "episode:  304 score: 245.95  average score 197.19\n",
      "episode:  305 score: 219.18  average score 199.11\n",
      "episode:  306 score: 298.57  average score 199.87\n",
      "episode:  307 score: 203.01  average score 199.89\n",
      "episode:  308 score: 3.67  average score 200.68\n",
      "episode:  309 score: 266.09  average score 201.60\n",
      "episode:  310 score: 246.54  average score 202.73\n",
      "episode:  311 score: 249.46  average score 203.01\n",
      "episode:  312 score: 266.13  average score 203.16\n",
      "episode:  313 score: 220.33  average score 203.43\n",
      "episode:  314 score: 154.13  average score 202.94\n",
      "episode:  315 score: 178.42  average score 202.18\n",
      "episode:  316 score: 161.89  average score 205.19\n",
      "episode:  317 score: 260.65  average score 205.68\n",
      "episode:  318 score: 251.61  average score 207.42\n",
      "episode:  319 score: 237.33  average score 207.16\n",
      "episode:  320 score: 280.22  average score 207.91\n",
      "episode:  321 score: 268.84  average score 208.51\n",
      "episode:  322 score: 290.73  average score 208.89\n",
      "episode:  323 score: 247.76  average score 209.03\n",
      "episode:  324 score: 222.23  average score 209.24\n",
      "episode:  325 score: 218.57  average score 211.51\n",
      "episode:  326 score: 200.67  average score 211.43\n",
      "episode:  327 score: 208.47  average score 211.09\n",
      "episode:  328 score: 279.15  average score 211.16\n",
      "episode:  329 score: 216.44  average score 210.95\n",
      "episode:  330 score: 196.39  average score 211.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  331 score: 294.00  average score 211.67\n",
      "episode:  332 score: 295.31  average score 212.49\n",
      "episode:  333 score: 241.41  average score 212.30\n",
      "episode:  334 score: 251.25  average score 212.45\n",
      "episode:  335 score: 233.26  average score 212.16\n",
      "episode:  336 score: 244.64  average score 212.02\n",
      "episode:  337 score: 235.63  average score 211.86\n",
      "episode:  338 score: 250.58  average score 212.48\n",
      "episode:  339 score: 210.88  average score 212.45\n",
      "episode:  340 score: 218.31  average score 211.86\n",
      "episode:  341 score: 282.19  average score 213.46\n",
      "episode:  342 score: 227.87  average score 216.55\n",
      "episode:  343 score: 232.26  average score 216.06\n",
      "episode:  344 score: 234.18  average score 215.72\n",
      "episode:  345 score: 236.96  average score 215.75\n",
      "episode:  346 score: 259.80  average score 215.91\n",
      "episode:  347 score: 261.82  average score 215.93\n",
      "episode:  348 score: 195.81  average score 215.78\n",
      "episode:  349 score: 255.60  average score 216.01\n",
      "episode:  350 score: 278.27  average score 216.48\n",
      "episode:  351 score: 264.98  average score 216.94\n",
      "episode:  352 score: 281.31  average score 220.40\n",
      "episode:  353 score: 230.48  average score 221.77\n",
      "episode:  354 score: 245.84  average score 221.69\n",
      "episode:  355 score: 230.27  average score 221.49\n",
      "episode:  356 score: 240.47  average score 221.24\n",
      "episode:  357 score: 284.36  average score 221.53\n",
      "episode:  358 score: 210.61  average score 221.83\n",
      "episode:  359 score: 294.05  average score 222.57\n",
      "episode:  360 score: -1.99  average score 219.98\n",
      "episode:  361 score: 238.46  average score 222.98\n",
      "episode:  362 score: 303.05  average score 227.17\n",
      "episode:  363 score: 258.77  average score 227.45\n",
      "episode:  364 score: 218.21  average score 227.16\n",
      "episode:  365 score: 197.71  average score 225.99\n",
      "episode:  366 score: 261.70  average score 225.95\n",
      "episode:  367 score: 207.88  average score 225.19\n",
      "episode:  368 score: 265.64  average score 225.73\n",
      "episode:  369 score: 16.38  average score 223.60\n",
      "episode:  370 score: 274.15  average score 223.96\n",
      "episode:  371 score: 247.31  average score 223.32\n",
      "episode:  372 score: 248.48  average score 222.82\n",
      "episode:  373 score: 261.90  average score 224.34\n",
      "episode:  374 score: 286.93  average score 225.54\n",
      "episode:  375 score: 245.99  average score 225.42\n",
      "episode:  376 score: 246.74  average score 225.23\n",
      "episode:  377 score: 244.00  average score 225.16\n",
      "episode:  378 score: 254.02  average score 225.70\n",
      "episode:  379 score: 242.33  average score 226.09\n",
      "episode:  380 score: 246.50  average score 226.50\n",
      "episode:  381 score: 286.98  average score 227.34\n",
      "episode:  382 score: 263.96  average score 227.14\n",
      "episode:  383 score: 215.39  average score 226.30\n",
      "episode:  384 score: 255.91  average score 226.25\n",
      "episode:  385 score: -71.91  average score 225.95\n",
      "episode:  386 score: 249.77  average score 228.53\n",
      "episode:  387 score: 285.90  average score 229.21\n",
      "episode:  388 score: 281.35  average score 229.62\n",
      "episode:  389 score: 261.85  average score 233.34\n",
      "episode:  390 score: 252.86  average score 233.61\n",
      "episode:  391 score: 267.59  average score 234.72\n",
      "episode:  392 score: 263.96  average score 234.68\n",
      "episode:  393 score: 279.89  average score 234.37\n",
      "episode:  394 score: 254.97  average score 234.30\n",
      "episode:  395 score: 283.97  average score 234.59\n",
      "episode:  396 score: 264.18  average score 235.10\n",
      "episode:  397 score: 285.86  average score 235.09\n",
      "episode:  398 score: 272.57  average score 235.33\n",
      "episode:  399 score: 292.35  average score 236.00\n",
      "episode:  400 score: 282.28  average score 236.38\n",
      "episode:  401 score: 263.74  average score 236.92\n",
      "episode:  402 score: 259.78  average score 239.31\n",
      "episode:  403 score: 287.97  average score 239.75\n",
      "episode:  404 score: 233.97  average score 239.15\n",
      "episode:  405 score: 247.09  average score 239.16\n",
      "episode:  406 score: 265.33  average score 239.62\n",
      "episode:  407 score: -24.37  average score 236.42\n",
      "episode:  408 score: 216.01  average score 236.55\n",
      "episode:  409 score: 51.81  average score 237.03\n",
      "episode:  410 score: 269.65  average score 237.06\n",
      "episode:  411 score: 279.17  average score 237.38\n",
      "episode:  412 score: 314.95  average score 238.03\n",
      "episode:  413 score: 265.65  average score 238.03\n",
      "episode:  414 score: 19.11  average score 236.04\n",
      "episode:  415 score: 250.06  average score 236.99\n",
      "episode:  416 score: 7.91  average score 235.30\n",
      "episode:  417 score: 299.13  average score 236.66\n",
      "episode:  418 score: 246.00  average score 236.51\n",
      "episode:  419 score: 299.91  average score 236.99\n",
      "episode:  420 score: 237.33  average score 236.99\n",
      "episode:  421 score: 244.10  average score 236.63\n",
      "episode:  422 score: 242.84  average score 236.37\n",
      "episode:  423 score: 266.72  average score 236.14\n",
      "episode:  424 score: 200.26  average score 235.67\n",
      "episode:  425 score: 268.50  average score 236.12\n",
      "episode:  426 score: 273.45  average score 236.67\n",
      "episode:  427 score: 249.18  average score 237.15\n",
      "episode:  428 score: 221.39  average score 237.28\n",
      "episode:  429 score: -133.71  average score 233.19\n",
      "episode:  430 score: 266.19  average score 233.68\n",
      "episode:  431 score: 270.00  average score 234.41\n",
      "episode:  432 score: 240.68  average score 233.88\n",
      "episode:  433 score: 255.18  average score 233.48\n",
      "episode:  434 score: 265.22  average score 233.72\n",
      "episode:  435 score: 217.96  average score 233.39\n",
      "episode:  436 score: 295.79  average score 234.01\n",
      "episode:  437 score: 238.21  average score 233.95\n",
      "episode:  438 score: 298.35  average score 234.57\n",
      "episode:  439 score: -162.98  average score 230.47\n",
      "episode:  440 score: 237.50  average score 230.74\n",
      "episode:  441 score: 299.15  average score 231.54\n",
      "episode:  442 score: 269.66  average score 231.41\n",
      "episode:  443 score: 251.87  average score 231.65\n",
      "episode:  444 score: 278.19  average score 232.10\n",
      "episode:  445 score: 240.09  average score 232.16\n",
      "episode:  446 score: 250.85  average score 232.30\n",
      "episode:  447 score: 243.20  average score 232.14\n",
      "episode:  448 score: 230.61  average score 231.83\n",
      "episode:  449 score: 290.82  average score 232.77\n",
      "episode:  450 score: -127.41  average score 228.98\n",
      "episode:  451 score: 238.71  average score 228.58\n",
      "episode:  452 score: 264.73  average score 228.58\n",
      "episode:  453 score: 265.18  average score 228.42\n",
      "episode:  454 score: -106.61  average score 225.08\n",
      "episode:  455 score: 245.94  average score 225.08\n",
      "episode:  456 score: 255.70  average score 225.34\n",
      "episode:  457 score: -144.02  average score 221.53\n",
      "episode:  458 score: 268.48  average score 221.37\n",
      "episode:  459 score: 275.23  average score 222.01\n",
      "episode:  460 score: 233.32  average score 221.41\n",
      "episode:  461 score: 210.69  average score 223.52\n",
      "episode:  462 score: 266.76  average score 223.80\n",
      "episode:  463 score: 249.25  average score 223.26\n",
      "episode:  464 score: 253.16  average score 223.21\n",
      "episode:  465 score: 247.85  average score 223.50\n",
      "episode:  466 score: 272.41  average score 224.24\n",
      "episode:  467 score: 229.35  average score 223.92\n",
      "episode:  468 score: 262.66  average score 224.46\n",
      "episode:  469 score: 261.59  average score 224.42\n",
      "episode:  470 score: 244.56  average score 226.68\n",
      "episode:  471 score: -19.78  average score 223.77\n",
      "episode:  472 score: -15.74  average score 221.17\n",
      "episode:  473 score: 246.51  average score 221.15\n",
      "episode:  474 score: 259.13  average score 221.12\n",
      "episode:  475 score: 245.01  average score 220.71\n",
      "episode:  476 score: 296.67  average score 221.21\n",
      "episode:  477 score: 256.75  average score 221.31\n",
      "episode:  478 score: 225.70  average score 221.13\n",
      "episode:  479 score: 289.92  average score 221.48\n",
      "episode:  480 score: 249.29  average score 221.55\n",
      "episode:  481 score: 228.89  average score 221.38\n",
      "episode:  482 score: 300.89  average score 221.51\n",
      "episode:  483 score: 234.51  average score 221.22\n",
      "episode:  484 score: 302.17  average score 222.08\n",
      "episode:  485 score: 272.67  average score 222.25\n",
      "episode:  486 score: 299.96  average score 225.93\n",
      "episode:  487 score: 239.87  average score 225.83\n",
      "episode:  488 score: 291.59  average score 225.89\n",
      "episode:  489 score: 280.16  average score 225.88\n",
      "episode:  490 score: 258.16  average score 225.84\n",
      "episode:  491 score: 224.43  average score 225.56\n",
      "episode:  492 score: 0.17  average score 222.91\n",
      "episode:  493 score: 220.87  average score 222.48\n",
      "episode:  494 score: 279.08  average score 222.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  495 score: 270.76  average score 222.63\n",
      "episode:  496 score: 252.13  average score 222.32\n",
      "episode:  497 score: -14.48  average score 219.56\n",
      "episode:  498 score: 308.67  average score 219.78\n",
      "episode:  499 score: 265.62  average score 219.71\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b555a5d5b050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lunarlander-ddqn.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_games\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mplotLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddqn_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-1c50fad9f7e3>\u001b[0m in \u001b[0;36mplotLearning\u001b[1;34m(x, scores, epsilons, filename, lines)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplotLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0max2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('LunarLander-v2')\n",
    "    ddqn_agent = DDQNAgent(alpha=0.0005, gamma=0.99, n_actions=4, epsilon=1.0, batch_size=64, input_dims=8)\n",
    "    n_games = 500\n",
    "    \n",
    "    ddqn_scores = []\n",
    "    eps_history = []\n",
    "    \n",
    "    #env = wrappers.Monitor(env, 'tmp/lunar-lander', video_callable=lambda episode_id: True, force=True)\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        done = False\n",
    "        score = 0\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            action = ddqn_agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action) #state: observation, new_state: observation_\n",
    "            score += reward\n",
    "            ddqn_agent.remember(observation, action, reward, observation_, done)\n",
    "            observation = observation_\n",
    "            ddqn_agent.learn()\n",
    "        eps_history.append(ddqn_agent.epsilon)\n",
    "        ddqn_scores.append(score)\n",
    "        \n",
    "        avg_score = np.mean(ddqn_scores[max(0, i-100):(i+1)])\n",
    "        #print('episode ', i, 'score %.2f' % score, 'average score %.2f', % avg_score)\n",
    "        print('episode: ', i,'score: %.2f' % score,\n",
    "              ' average score %.2f' % avg_score)\n",
    "        \n",
    "        if i % 10 == 0 and i > 0:\n",
    "            ddqn_agent.save_model()\n",
    "    \n",
    "    filename = 'lunarlander-ddqn.png'\n",
    "    x = [i + 1 for i in range(n_games)]\n",
    "    plotLearning(x, ddqn_scores, eps_history, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size, input_shape, n_actions, discrete=False):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.discrete = discrete\n",
    "        self.state_memory = np.zeros((self.mem_size, input_shape))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, input_shape))\n",
    "        dtype = np.int8 if self.discrete else np.float32\n",
    "        self.action_memory = np.zeros((self.mem_size, n_actions), dtype=dtype)\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        # store one hot encoding of actions, if appropriate\n",
    "        if self.discrete:\n",
    "            actions = np.zeros(self.action_memory.shape[1])\n",
    "            actions[action] = 1.0\n",
    "            self.action_memory[index] = actions\n",
    "        else:\n",
    "            self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = 1 - done\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, batch_size)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, terminal\n",
    "\n",
    "def build_dqn(lr, n_actions, input_dims, fc1_dims, fc2_dims):\n",
    "    model = Sequential([\n",
    "                Dense(fc1_dims, input_shape=(input_dims,)),\n",
    "                Activation('relu'),\n",
    "                Dense(fc2_dims),\n",
    "                Activation('relu'),\n",
    "                Dense(n_actions)])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "class DDQNAgent(object):\n",
    "    def __init__(self, alpha, gamma, n_actions, epsilon, batch_size,\n",
    "                 input_dims, epsilon_dec=0.996,  epsilon_end=0.01,\n",
    "                 mem_size=1000000, fname='ddqn_model.h5', replace_target=100):\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.n_actions = n_actions\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_dec = epsilon_dec\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.model_file = fname\n",
    "        self.replace_target = replace_target\n",
    "        self.memory = ReplayBuffer(mem_size, input_dims, n_actions,\n",
    "                                   discrete=True)\n",
    "        self.q_eval = build_dqn(alpha, n_actions, input_dims, 256, 256)\n",
    "        self.q_target = build_dqn(alpha, n_actions, input_dims, 256, 256)\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            actions = self.q_eval.predict(state)\n",
    "            action = np.argmax(actions)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr > self.batch_size:\n",
    "            state, action, reward, new_state, done = \\\n",
    "                                          self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "            action_values = np.array(self.action_space, dtype=np.int8)\n",
    "            action_indices = np.dot(action, action_values)\n",
    "\n",
    "            q_next = self.q_target.predict(new_state)\n",
    "            q_eval = self.q_eval.predict(new_state)\n",
    "            q_pred = self.q_eval.predict(state)\n",
    "\n",
    "            max_actions = np.argmax(q_eval, axis=1)\n",
    "\n",
    "            q_target = q_pred\n",
    "\n",
    "            batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "\n",
    "            q_target[batch_index, action_indices] = reward + \\\n",
    "                    self.gamma*q_next[batch_index, max_actions.astype(int)]*done\n",
    "\n",
    "            _ = self.q_eval.fit(state, q_target, verbose=0)\n",
    "\n",
    "            self.epsilon = self.epsilon*self.epsilon_dec if self.epsilon > \\\n",
    "                           self.epsilon_min else self.epsilon_min\n",
    "            if self.memory.mem_cntr % self.replace_target == 0:\n",
    "                self.update_network_parameters()\n",
    "\n",
    "    def update_network_parameters(self):\n",
    "        self.q_target.model.set_weights(self.q_eval.model.get_weights())\n",
    "\n",
    "    def save_model(self):\n",
    "        self.q_eval.save(self.model_file)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.q_eval = load_model(self.model_file)\n",
    "        # if we are in evaluation mode we want to use the best weights for\n",
    "        # q_target\n",
    "        if self.epsilon == 0.0:\n",
    "            self.update_network_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
